# 并发设计的内涵

在最基本的层面上，并发数据结构的设计意图是让多线程并发访问。只要满足以下条件，就认为这是一个线程安全（thread-safe）的数据结构：

1. 多线程执行的操作无论异同，每个线程所见的数据结构都是自恰的；
2. 数据不会丢失或破坏，所有不变量终将成立，恶性条件竞争也不会出现。

<b><font color=green>真正的并发设计意义在于提供更高的并发程度，让各线程有更多机会按并发方式访问数据结构。</font></b>顾名思义，互斥使多个访问互相排斥：在一个互斥上，每次只可能让一个线程获取锁(线程轮流访问互斥保护的数据,非并发访问)，这种行为称为串行化(serialization)。相对而言，某些数据结构更有潜质支持真正的并发访问：<b><font color=green>保护的范围越小，需要的串行化操作就越少，并发程度就可能越高。</font></b>

设计支持并发访问的数据结构，我们需要考虑两方面：

1. 确保访问安全。构建线程安全的数据结构：

    - 若某线程的行为破坏了数据结构的不变量，则必须确保其他任何线程都无法见到该状态。
    - 保持谨慎以排除函数接口固有的条件竞争，数据结构提供的操作应该完整、独立，而非零散的分解步骤。
    - 一旦程序抛出异常，要特别注意数据结构的行为，力保不变量不被破坏。
    - 在数据结构的使用过程中，限制锁对象的作用域，尽可能避免嵌套锁，从而将死锁的可能性降至最低。

    

    在深究上述细节之前，我们也应该想清楚，<b><font color=green>数据结构的使用者应该受到什么样的条件限制? 如果有线程能通过特定函数访问数据结构，那么哪些函数可以安全地跨线程调用？</font></b>这个问题很重要。<b>通常，构造函数和析构函数都要按排他方式执行。但数据结构的使用者须自行保证一点：在构造函数完成以前和析构函数开始之后，访问不会发生。</b>如果数据结构支持赋值、内部数据互换或拷贝构造等操作，且数据结构还具备多个处理函数，数据结构的设计者有责任决断：这些函数与其他操作一起并发调用是否安全，以及这些函数是否要求使用者保证以排他方式访问。

    

2. 实现真正的并发访问。数据结构的设计者需要考虑：

    - 能否限制锁的作用域，从而让操作的某些部分在锁保护以外执行？
    - 数据结构内部的不同部分能否采用不同的互斥？
    - 是否所有操作都需要相同程度的保护？
    - 能否通过简单的改动，提高数据结构的并发程度，为并发操作增加机会，而不影响操作语义？

# 基于锁的并发数据结构

<b><font color="green">设计基于锁的并发数据结构的关键是，要确保先锁定合适的互斥，再访问数据，并尽可能缩短持锁时间。</font></b>凭借一个互斥来保护整个数据结构，其难度也不小，我们需要：

1. 保证不得访问互斥锁以外的数据
2. 且成员函数接口不得存在固有的条件竞争。

若针对数据结构中的各部分分别采用独立互斥，这两个问题就会互相混杂而恶化。另外，假使并发数据结构上的操作需要锁住多个互斥，则可能会引发死锁。



下面实现线程安全的栈容器类定义

```C++
#include <exception>
#include <stack>
#include <mutex>
#include <memory>

struct empty_stack: std::exception {
    const char* what() const throw() {
        return "empty stack";
    }
};

template<typename T>
class threadsafe_stack {
private:
    std::stack<T> data;
    mutable std::mutex m;
public:
    threadsafe_stack(){}
    threadsafe_stack(const threadsafe_stack& other) {
        std::lock_guard<std::mutex> lock(other.m);
        data=other.data;
    }
    threadsafe_stack& operator=(const threadsafe_stack&) = delete;

    void push(T new_value) {
        std::lock_guard<std::mutex> lock(m);
		// 可能会抛异常(移动数据或底层栈扩展容量不足导致异常)
        // stack会保证自身的安全,没有问题
        data.push(std::move(new_value));
    }
	
    std::shared_ptr<T> pop() {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
		// 可能是内存不足而无法为新对象分配空间,可能分配了内存空间
		// 无法为引用计数而设的内部数据分配空间
		// 也可能在数据的移动/复制过程中,其复制构造函数或移动构造函数抛出异常
		// C++会保证不出现内存泄漏
        std::shared_ptr<T> const res(
			std::make_shared<T>(std::move(data.top())));
		// 不会抛出异常
        data.pop();
        return res;
    }
	
	void pop(T& value) {
        std::lock_guard<std::mutex> lock(m);
        if(data.empty()) throw empty_stack();
		// 拷贝赋值操作符或移动赋值操作符会抛出异常
		// 但数据未改动,安全 
        value=std::move(data.top());
        data.pop();
    }

    bool empty() const {
        std::lock_guard<std::mutex> lock(m);
        return data.empty();
    }
};
```

按照构建访问安全的数据结构的指引来检查上述代码实现：

1. 每个成员函数都在内部互斥m之上加锁，这保障了基本的线程安全。
2. 在`empty()`和每个`pop()`重载之间，都潜藏着数据竞争的隐患。然而，`pop()`函数不仅可以加锁，其还可以明文判别内部的栈容器是否为空，所以这不属于恶性数据竞争。以上设计并未沿用`std::stack<>`的既有模式，即提供两个分离的成员函数`top()`和`pop()`，而是让`pop()`直接返回弹出的数据，避开了原本可能存在的数据竞争。
3. 有几个操作可能会产生异常，上述代码上有分析，都是安全行为
4. 上述实现可能会引起死锁。原因是在持锁期间执行用户代码：栈容器所含的数据中，有用户自定义的复制构造函数、移动构造函数、拷贝赋值操作符和移动赋值操作符，用户也有可能自行重载`new`操作符。假使栈容器要插入或移除数据，在操作过程中数据自身调用了上述函数，则可能再进一步调用栈容器的成员函数，因而需要获取锁，但相关的互斥却已被锁住，最后导致死锁。向栈容器添加/移除数据，却不涉及复制行为或内存分配，这是不合理的。合理的解决方式是对栈容器的使用者提出要求，由他们负责保证避免以上死锁场景。
5. 栈容器的所有成员函数都使用`std::lock_guard<>`保护数据，同时调用各成员函数的线程没有数量限制。仅有构造函数和析构函数不是安全的成员函数。若对象未完成构造或销毁到一半，转去调用成员函数，那么无论是否按并发方式执行，这都不正确。所以，必须由使用者自己保证：若栈容器还未构建完成，则其他线程不得访问数据，并且，只有当全部线程都停止访问之后，才可销毁栈容器。

上述实现，锁的排他性迫使各个线程串行，应用的性能会因此而受限。



## 利用锁和条件变量实现线程安全的队列

