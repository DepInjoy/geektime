并行计算机中，每个CPU单元都可能含有Cache，所以需要考虑所有CPU之间的Cache数据同步机制。
目前最常用的方法是基于目录的Cache一致性协议。当一个CPU写内存时，要查找目录表，如果该内存单元在其他CPU中含有备份，则向其他CPU发送广播通知。目标CPU收到通知后，更新自身包含的Cache数据。Cache目录一致既适用于SMP也适用于NUMA。Cache目录一致性实现了多个CPU之间的Cache同步，但是不同计算机对Cache更新通知的时序规定了不同的原则。

- 强一致性：系统中所有更新Cache的通知要执行结束，才允许各CPU执行后续的访存指令。这种方式使所有处理器核之间严格保证Cache一致性，但是会使各CPU花费大量时间等待Cache通知结束，从而降低了系统性能。
- 弱一致性：各CPU不需要等待所有Cache通知执行结束，就可以执行访存指令。在这种情况下，CPU硬件不维护所有Cache的强制一致性，某一个CPU写内存的行为可能不会及时通知到所有其他CPU，这时不同的CPU会在Cache中读取出不同的数值。如果程序员觉得在有些程序中必须保证强一致性，可以调用CPU提供的一条“内存同步指令”，强行使CPU等待所有Cache更新结束。

目前绝大多数实际的并行CPU都采用弱一致性。弱一致性让程序员承担了维护代价，但是性能比强一致性要高很多倍。程序员在编写并行算法时，对于多个线程要访问相同内存单元的位置，只需要适当插入“内存同步指令”来使线程程“看”到一致的数据。

# 原子指令

原子指令(Atomic Instruction)用于在多个CPU之间维护同步关系。在一些科学计算问题中，通过并行算法把子问题分配到多个CPU上执行，但是各个子问题之间存在合作关系，因此需要硬件机制来实现多个CPU之间的同步。

一个典型的同步例子是“原子加1”问题。例如，一个CPU要对内存单元M中的数据加1，这个动作需要3条指令来完成：

1. 读M的值到寄存器R
2. 对R执行加1运算
3. 把R的值写回内存单元M。

<center>
    <img src="./img/Atomic_CPU_Sync.png">
</center>

如果计算机中只有一个CPU，执行上面3条指令不会有任何问题。但是如果CPU有两个，则可能在一个CPU执行过程中，另一个CPU也执行这3条指令，最后M的结果不是增加2而是增加1。原子指令可以实现一个CPU独占执行时间。使用原子指令把连续多条指令包含起来，计算机保证只有一个CPU处于执行状态，其他CPU必须等待原子指令结束才能继续执行。

# 内存模型

内存模型精确定义了基础构建单元应当如何运转。

内存模型牵涉两个方面：基本结构和并发。基本结构关系到整个程序在内存中的布局，它对并发很重要，尤其是在分析底层原子操作时。就C++而言，归根结底，基本结构就是对象和内存区域。

C++程序的数据全部都由对象构成，C++标准只将“对象”定义为“某一存储范围”(a region of storage)。不论对象属于什么类型，它都会存储在一个或多个内存区域中。每个内存区域或是对象/子对象，属于标量类型(scalar type)，如`unsigned short`和`my_class*`，或是一串连续的位域(bit field)。其中位域有一个重要性质：尽管相邻的位域分属不同对象，但照样算作同一内存区域。

<center>
    <img src="./img/5_1_StructRegionStorage.png">
	</br>
    <div><b>将Struct分解为对象和内存区域</b></div>
</center>

`bf3`是0宽度位域（其变量名被注释掉，因为0宽度位域必须匿名），与`bf4`彻底分离，将`bf4`排除在`bf3`的内存区域之外，但`bf3`实际上并不占有任何内存区域。

需要牢记的要点：

1. 每一个变量都是一个对象，其成员变量也是对象。
2. 每个对象至少占用一个内存区域(Memory Location)。
3. 若变量属于内建基本类型(如`int`或`char`)，则不论其大小，都占用一块内存区域(且仅此一块)，即便它们的位置相邻或它们是数列中的元素。
4. 相邻位域属于同一内存区域。(在C++和C中规定，宽度为0的一个未命名位域强制下一位域对齐到其下一type边界)



# 同步操作和强制次序

## 栅栏
如果缺少栅栏(fence)功能，原子操作的程序库就不完整。栅栏具备多种操作，用途是强制施加内存次序，却无须改动任何数据。通常，它们与服从memory_order_relaxed次序的原子操作组合使用。栅栏操作全部通过全局函数执行。当线程运行至栅栏处时，它便对线程中其他原子操作的次序产生作用。栅栏也常常被称作“内存卡”或“内存屏障”，其得名原因是它们在代码中划出界线，限定某些操作不得通行。针对不同变量上的宽松操作，编译器或硬件往往可以自主对其进行重新编排。栅栏限制了这种重新编排。在一个多线程程序中，可能原来并非处处具备先行关系和同步关系，栅栏则在欠缺之处引入这两种关系。

栅栏可以令宽松操作服从一定的次序。
```C++
#include <atomic>
#include <thread>
#include <assert.h>
std::atomic<bool> x,y;
std::atomic<int> z;

void write_x_then_y() {
    // 1.1: 变量x的存储操作
    x.store(true,std::memory_order_relaxed);
    // 2.1 加入释放栅栏
    //  释放栅栏,令变量y的存储操作不再服从memory_order_relaxed次序
    //  改用了次序memory_order_release一样
    std::atomic_thread_fence(std::memory_order_release);
    y.store(true,std::memory_order_relaxed);
}

void read_y_then_x() {
    while(!y.load(std::memory_order_relaxed));
    // 2.2 加入获取栅栏,两个栅栏形成同步,使得1.1肯定在1.2之前
    //   获取栅栏使得变量y的载入如改用memory_order_acquire次序一样
    std::atomic_thread_fence(std::memory_order_acquire);
    // 1.2:载入x,栅栏同步使得x读取的值必定为true
    if(x.load(std::memory_order_relaxed)) {
        ++z;
    }
}

int main(int argc, char*argv[]) {
    x = false;
    y = false;
    z = 0;
    std::thread a(write_x_then_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    // 两个栅栏形成同步,这里的断言定不会发生
    assert(z.load()!=0);
    return 0;
}
```

加入栅栏之前，变量x的存储操作和读取操作是没有确定次序的，故此断言有可能触发。加入的两个栅栏都有必要：一个线程需要进行释放操作，另一个线程则需进行获取操作，唯有配对才可以构成同步关系。

栅栏的整体运作思路是：若存储操作处于释放栅栏后面，而存储操作的结果为获取操作所见，则该释放栅栏与获取操作同步；若载入操作处于获取栅栏前面，而载入操作见到了释放操作的结果，则该获取栅栏与释放操作同步。

