<center>
    <img src="./img/00_spark_arch.png">
    <div>Spark整体架构图</div>
</center>

Driver是用户编写的数据处理逻辑，这个逻辑中包含用户创建的SparkContext。SparkContext是用户逻辑与Spark集群主要的交互接口，它会和Cluster Manager交互，包括向它申请计算资源等。Cluster Manager负责集群的资源管理和调度，现在支持Standalone、Apache Mesos和YARN。Worker Node是集群中可以执行计算任务的节点,负责启动Executor。Executor是在一个Worker Node上为应用程序启动的进程，该进程负责运行任务，并将数据存在内存或者磁盘上。Task是被送到某个Executor上的计算单元。每个应用都有各自独立的Executor，计算最终在计算节点的Executor中执行。

# 术语

Executor是在Worker节点上为应用程序启动的进程，负责运行任务。每个Executor都在其自己的Java进程中运行Executor在应用程序的整个生命周期内都存在，它们可以并行处理多个任务。

Worker是Spark集群中的节点，它们负责启动Executor。Worker节点可以有一个或多个Executor

Task是Spark作业执行的最小单位。每个Executor都有多个Task，一个Task是一个线程，对应了一个任务。在基于RDD计算时，Task的数量其实就是RDD的分区数，RDD的分区数目决定了总的Task数量。每个Task执行的结果就是生成了目标RDD的一个partition。


## Cores(Slots)
Cores(Slots)：在Spark中，Cores(或Slots)是每个Executor(也可能是Spark守护进程)可用的线程数。Slots表示可用于为Spark执行并行工作的线程[。Spark文档经常将这些线程称为Cores，实际上Cores和机器上的物理核心没有关系。在[stackoverflow:Spark local mode: How to query the number of executor slots?](https://stackoverflow.com/questions/49324721/spark-local-mode-how-to-query-the-number-of-executor-slots)中给出了这两个术语的渊源：

> "Slots" is a term Databricks uses (or used?) for the **threads available** to do parallel work for Spark. The Spark documentation and Spark UI **calls the same concept "cores"**, even though they are unrelated to physical CPU cores.
>
>
> 翻译一下的意思是说：
>
> Slots是Databricks使用(或曾用)的术语，用来表示在Spark上并行运行可用的线程数。Spark文档和UI将这个该概念称为Cores，实际上它和机器的物理CPU核心无关。

## 延迟调度
在Apache Spark中，延迟调度(Delay Scheduling)是一种优化策略，用于改善数据本地性。以下是一些关键的延迟调度概念：

1. 数据本地性：Spark任务的执行效率往往取决于其所处理数据的位置。例如，如果一个任务在同一节点上的数据上运行，那么它的执行速度通常会比在远程节点上的数据上运行要快。这就是所谓的数据本地性。

2. 延迟调度：为了优化数据本地性，Spark引入了一种名为延迟调度的策略。当Spark准备调度一个任务时，它首先会检查该任务所需数据的位置。如果数据位于某个节点上，Spark会尝试在该节点上调度任务。然而，如果该节点当前没有可用的CPU核心，Spark不会立即在其他节点上调度任务。相反，它会等待一段时间，希望在等待期间该节点能够释放出CPU核心。这就是所谓的延迟调度。

相关配置参数：`spark.locality.wait`配置参数来设置延迟调度的等待时间。`spark.locality.wait.node`和`spark.locality.wait.process`配置参数来分别设置节点级别和进程级别的等待时间。

## Barrier TaskSet

在Apache Spark中，Barrier TaskSet是一种特殊的任务集，它用于支持Barrier Execution Mode。以下是一些关键的Barrier TaskSet概念：

1. Barrier Execution Mode：一种执行模式，它要求在同一阶段的所有任务同时开始，并在所有任务完成后同时结束。这种执行模式常用于深度学习和其他需要全局同步的应用。

2. Barrier TaskSet：在Barrier Execution Mode中，一个Barrier TaskSet包含了在同一阶段的所有任务。这些任务在开始时会设置一个全局的屏障，并等待所有任务达到这个屏障。

3. BarrierTaskContext：提供了额外的上下文信息和工具的TaskContext，用于Barrier Stage中的任务。你可以使用BarrierTaskContext.get()来获取一个正在运行的Barrier Task的Barrier Context。

# 参考资料

1. [Datacadamia:Spark-Core(Slot)](https://datacadamia.com/db/spark/cluster/core)

