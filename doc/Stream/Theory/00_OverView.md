# DAG(有向无环图)

从流式计算的计算任务拓扑结构角度来看，一般的流式计算任务都是由计算节点和流式数据组成的DAG。DAG中的顶点是算子，表示计算，边表示数据依赖关系。DAG的节点一般是完成一个计算任务所需要的各种处理功能，比如过滤、数值累加、Join等具体计算功能，而流经各个计算节点的实时数据流构成了DAG的有向边。



# 计算系统架构

常见的流式计算系统架构分为两种：主从模式（Master-Slave）和P2P模式。大多数系统架构遵循主从模式，主要是因为主控节点做全局管理比较简洁，比如Storm、MillWheel和Samza，P2P架构无中心控制节点，S4是P2P架构。其中，。Samza是利用消息系统Kafka和Hadoop 2.0的资源管理系统YARN综合而成的，可以理解为是在YARN平台之上的一个应用计算框架，从本质上讲，也遵循主从架构。

# 主从架构

Storm中有主控节点和工作节点，主控节点上运行Nimbus，其主要职责是分发计算代码、在机器间分配计算任务以及故障检测等管理功能；主控节点上运行Nimbus，其主要职责是分发计算代码、在机器间分配计算任务以及故障检测等管理功能。ZooKeeper集群用来协调Nimbus和Supervisor之间的工作，Storm将两者的状态信息存储在ZooKeeper集群上，这样Nimbus和Supervisor都成为无状态的服务节点，可以方便地进行故障恢复，无论哪个构件发生故障，都可以随时在另外一台机器上快速重新启动而不会丢失任何状态信息，但是，具体的DAG流式计算任务的计算节点可能是有状态的。

<b><font color="orange">zk上需要存储那些信息？</font></b>



## P2P架构

S4采用了P2P架构，没有中心控制节点，集群中的每台机器既负责任务计算，同时也做一部分系统管理工作，每个节点功能对等，这样的好处是系统可扩展性和容错性能好，不会产生主从模式中的单点失效问题，但管理复杂。

PE（Processing Element）是基本计算单元，属于DAG任务的计算节点，其接收到数据后触发用户应用逻辑对数据进行处理，并可能产生送向下游计算节点的衍生数据。PN（Processing Node）是PE运行的逻辑宿主（物理主机与逻辑宿主存在一对多关系），其中的事件监听器负责监听管理消息和应用数据，PEC调用对应的PE执行应用逻辑，分发器在通信层的帮助下分发数据，发送器负责对外产生衍生数据。通信层主要负责集群管理、自动容错以及逻辑宿主到物理节点的映射等功能，其可以自动侦测硬件故障，并做故障切换以及修正逻辑宿主和物理节点映射表。通信层利用ZooKeeper来协助管理P2P集群。

<center>
    <img src="./img/S4_Arch.png">
</center>



S4有一个比较严重的问题是没有合理的应用状态持久化策略，当机器出现故障时，可能存在应用状态信息丢失的问题。



## Smaza架构

<center>
    <img src="./img/Smaza_Arch.png">
</center>

Smaza是在Kafka和YARN之上封装了流式计算语义API的系统，其中，Kafka负责数据流的存储与管理，YARN负责资源管理、系统执行调度和系统容错等功能，Samza API则提供了描述执行流式计算DAG任务的接口。



Samza的任务执行流程:

<center>
    <img src="./img/Smaza_Runtime.png">
</center>



1. 通过YARN客户端向资源管理器(RM)提交任务。
2. RM从节点管理器(NM)分配计算容器给Samza的应用管理器(AM)，计算容器包含了计算所需内存、CPU等各种资源。
3. 资源分配成功，YARN在容器内启动Samza AM，Samza AM起到类似于Hadoop 1.0中JobTracker的功能，负责具体计算任务的管理协调等功能。
4. Samza AM向RM申请一个或者多个容器启动Samza任务运行器(Task Runner)，任务运行器执行用户编码的应用逻辑，其对应的输入流和输出流都通过Kafka Broker来进行管理。

这样，一个Samza流式计算任务就可以启动起来并执行。

# 任务故障

<b><font color="orange">对于长期运行的流式作业，每个任务都谁是会出现故障，如何确保能够透明地处理这些故障，让流式作业可以继续运行。要实现这一点需要保证任务故障时可以继续运行，还需要保证结果和算子状态的正确性。</font></b>

对于流处理中的每个事件，任务都要执行以下几步：①接收事件并将它们存在本地缓冲区；②选择性更新内部状态；③产生输出记录。以上每步都可能发生故障，系统必须在故障情况下明确定义其行为。如果故障发生在第一步，事件是否会丢失？如果更新内部状态后发生故障，系统恢复后是否会重复更新？上述情况下，结果是否正确？



## 结果保障

结果保障指的是流处理引擎内部状态的一致性，也就是关注故障恢复后应用代码能够看到的状态。需要注意的是，保证应用状态的一致性和保证输出的一致性不是一回事。

---

**至多一次(At-Most Once Delivery)**

它保证每个事件至多被处理一次，也就是说没有机制来保证结果的正确性。上游节点不能保证消息被送达到下游节点。如果计算系统容错机制不完善，存在丢数据的可能性。`S4`和`MUDP8`属于这种类型。

---

 **至少一次(At-Least Once Delivery)**

对于大多数应用，用户不希望丢数据，这类保证称为至少一次。上游节点保证向下游节点送达一次或者多次相同的数据。所欲的数据都会被处理，但是有些数据可能会被处理多次。如果正确性仅依赖于信息的完整性，重复处理可以接受。例如，确定某个事件是否在输入流中出现过，可以采用至少一次保障正确实现；但如果要计算某个事件在输入流中出现的次数，至少一次保障会导致错误的计算结果。

为保证至少一次结果语义的正确性，需要在源头或缓冲区中去重。持久化时间日志会将所有的事件写入永久存储，这样可以在任务故障恢复时重放他们。一种实现方式是采用记录确认(record-acknowledgments)，它会将所有的数据都存在缓冲区中，直到处理管道中所有的任务都确认某个事件已经处理完毕才将数据丢弃。

---

**精确一次(Exact-Once Delivery)**

上游节点保证将流数据正确地送达下游节点且只正确送达一次。它表示没有数据的丢失，而且每个事件对于内部状态的更新都只有一次。本质上，精确一次保证意味着应用总会提供正确的结果如同故障没有发生过一样。`Storm`属于这种，它借助送达保证机制(实现至少送达一次)+事务拓扑(保证不会出现多次送达)联合完成。`Flink`也属于这种，它借助轻量级检查点机制来实现。

精确一致性保障以一次性保障为前提，同样需要数据重放，此外还需要流处理引擎保证内部状态的一致性，即在故障恢复后，引擎需要知道某个时间对应的更新是否已经反映在状态上。

---

**端到端的精确一次**

上面三个都属于应用状态的一致性。它在实际流处理中，处理流处理引擎还需要数据源组件和数据终点组件，端到端的精确一次指的是在整个数据管道上结果都是正确的。在每个组件都提供自身保证的情况下，整个数据管道上端到端保障受制于保障最弱的组件。在某些时候，可以借助弱保障来实现强语义，常见情况是求最大值或最小值的幂等操作，可以用至少一次保证来实现精确一次语义。

---

# 参考资料

1. 大数据日知录
2. 

